{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9327    1.0421   -0.78515   0.91033   0.22711  -0.62158  -1.6493\n",
      "  0.07686  -0.5868    0.058831  0.35628   0.68916  -0.50598   0.70473\n",
      "  1.2664   -0.40031  -0.020687  0.80863  -0.90566  -0.074054 -0.87675\n",
      " -0.6291   -0.12685   0.11524  -0.55685  -1.6826   -0.26291   0.22632\n",
      "  0.713    -1.0828    2.1231    0.49869   0.066711 -0.48226  -0.17897\n",
      "  0.47699   0.16384   0.16537  -0.11506  -0.15962  -0.94926  -0.42833\n",
      " -0.59457   1.3566   -0.27506   0.19918  -0.36008   0.55667  -0.70315\n",
      "  0.17157 ]\n",
      "down\n",
      "(24500, 250)\n",
      "down\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "wordsList=np.load('wordsList.npy') #包含40万个词的python列表\n",
    "wordsList=np.load('wordsList.npy') #包含40万个词的python列表\n",
    "wordsList=wordsList.tolist()\n",
    "wordsList=[word.decode('UTF-8') for word in wordsList]\n",
    "wordVectors=np.load('wordVectors.npy')\n",
    "baseballIndex=wordsList.index('baseball')\n",
    "print(wordVectors[baseballIndex])\n",
    "import pandas as pd\n",
    "#读入数据\n",
    "df=pd.read_csv('labeledTrainData.tsv',sep='\\t',escapechar='\\\\')\n",
    "\n",
    "numDimensions=300\n",
    "print(\"down\")\n",
    "\n",
    "maxSeqLength=250\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "#清洗数据，HTML字符使用空格替代\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "# #生成索引矩阵，得到24500*250的索引矩阵\n",
    "# ids=np.zeros((24500,maxSeqLength),dtype='int32')\n",
    "# #print(ids.shape) #输出结果为（24500,250）\n",
    "\n",
    "# fileCounter=0\n",
    "# for pf in range(0,len(df)): \n",
    "#     #print(pf)\n",
    "#     indexCounter=0\n",
    "#     cleanedLine=cleanSentences(df['review'][pf])\n",
    "#     split=cleanedLine.split()\n",
    "#     for word in split:\n",
    "#         try:\n",
    "#             #print('111')\n",
    "#             ids[fileCounter][indexCounter]=wordsList.index(word)\n",
    "#         except ValueError:\n",
    "#             ids[fileCounter][indexCounter]=399999\n",
    "#         indexCounter=indexCounter+1\n",
    "#         if indexCounter>=maxSeqLength:\n",
    "#             break        \n",
    "#     fileCounter=fileCounter+1 \n",
    "# print('down1')\n",
    "# np.save('C:/NLP/idsMatrix',ids)\n",
    "#上述注释后，将生成的索引矩阵保存到idsMatrix.npy文件中。避免了每次都要生成索引矩阵\n",
    "ids=np.load('idsMatrix.npy')\n",
    "print(ids.shape)\n",
    "\n",
    "#辅助函数\n",
    "from random import randint\n",
    "def getTrainBatch():\n",
    "    labels=[]\n",
    "    arr=np.zeros([batchSize,maxSeqLength])\n",
    "    i=0\n",
    "    for i in range(0,32):\n",
    "        j=0\n",
    "        while j<1:\n",
    "            num=randint(1,19600)\n",
    "            if df['sentiment'][num-1]==1:\n",
    "                j=j+1\n",
    "                labels.append([1,0])\n",
    "                arr[2*i]=ids[num-1:num]\n",
    "        j=0\n",
    "        while j<1:\n",
    "            num=randint(1,19600)\n",
    "            if df['sentiment'][num-1]==0:\n",
    "                j=j+1\n",
    "                labels.append([0,1])\n",
    "                arr[2*i+1]=ids[num-1:num]\n",
    "    return arr,labels\n",
    "print('down')\n",
    "\n",
    "\n",
    "batchSize=64 #批处理大小\n",
    "lstmUnits=64 #LSTM单元个数\n",
    "numClasses=2 #分类类别\n",
    "iterations=50000 #训练次数\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_800322/1376142830.py:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:760: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_800322/1376142830.py:12: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  lstmCell = tf.nn.rnn_cell.BasicLSTMCell(lstmUnits)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "/usr/local/lib/python3.8/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:757: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._bias = self.add_variable(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(1,), dtype=int32), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(1, ?, 64), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(3,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 2), dtype=float32)\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [None, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [None, maxSeqLength])\n",
    "data = tf.Variable(\n",
    "    tf.zeros([batchSize, maxSeqLength, numDimensions]), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors, input_data)\n",
    "\n",
    "# lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.nn.rnn_cell.BasicLSTMCell(lstmUnits)\n",
    "#lstmCell = tf.contrib.rnn.LSTMCell(lstm_units)\n",
    "# lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "drop = tf.nn.rnn_cell.DropoutWrapper(lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "pre=tf.nn.softmax(prediction)\n",
    "print(pre)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "print('down')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 03:22:20.514939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6\n",
      "2022-01-20 03:22:20.515507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22302 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1771: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i...1000 loss... 0.6392914056777954 accuracy 0.609375\n",
      "i...2000 loss... 0.6784121990203857 accuracy 0.546875\n",
      "i...3000 loss... 0.7337830066680908 accuracy 0.484375\n",
      "i...4000 loss... 0.41816359758377075 accuracy 0.796875\n",
      "i...5000 loss... 0.2896137535572052 accuracy 0.890625\n",
      "i...6000 loss... 0.2938542664051056 accuracy 0.875\n",
      "i...7000 loss... 0.2388550490140915 accuracy 0.9375\n",
      "i...8000 loss... 0.2884316146373749 accuracy 0.9375\n",
      "i...9000 loss... 0.2565196752548218 accuracy 0.90625\n",
      "i...10000 loss... 0.20505045354366302 accuracy 0.890625\n",
      "saved to /home/id-none/myfile/models1/pretrained_lstm.ckpt-10000\n",
      "i...11000 loss... 0.21898305416107178 accuracy 0.921875\n",
      "i...12000 loss... 0.20707285404205322 accuracy 0.953125\n",
      "i...13000 loss... 0.06143299490213394 accuracy 0.984375\n",
      "i...14000 loss... 0.057599231600761414 accuracy 0.96875\n",
      "i...15000 loss... 0.14526578783988953 accuracy 0.984375\n",
      "i...16000 loss... 0.035033874213695526 accuracy 1.0\n",
      "i...17000 loss... 0.007881193421781063 accuracy 1.0\n",
      "i...18000 loss... 0.02115922048687935 accuracy 1.0\n",
      "i...19000 loss... 0.00926268845796585 accuracy 1.0\n",
      "i...20000 loss... 0.008377986028790474 accuracy 1.0\n",
      "saved to /home/id-none/myfile/models1/pretrained_lstm.ckpt-20000\n",
      "i...21000 loss... 0.0338069349527359 accuracy 0.984375\n",
      "i...22000 loss... 0.0028619333170354366 accuracy 1.0\n",
      "i...23000 loss... 0.0024865325540304184 accuracy 1.0\n",
      "i...24000 loss... 0.007654092740267515 accuracy 1.0\n",
      "i...25000 loss... 0.001936773769557476 accuracy 1.0\n",
      "i...26000 loss... 0.005354316905140877 accuracy 1.0\n",
      "i...27000 loss... 0.003875979222357273 accuracy 1.0\n",
      "i...28000 loss... 0.002594634424895048 accuracy 1.0\n",
      "i...29000 loss... 0.004729975946247578 accuracy 1.0\n",
      "i...30000 loss... 0.0023282011970877647 accuracy 1.0\n",
      "saved to /home/id-none/myfile/models1/pretrained_lstm.ckpt-30000\n",
      "i...31000 loss... 0.0062926532700657845 accuracy 1.0\n",
      "i...32000 loss... 0.009796149097383022 accuracy 1.0\n",
      "i...33000 loss... 0.0029730424284934998 accuracy 1.0\n",
      "i...34000 loss... 0.006443017162382603 accuracy 1.0\n",
      "i...35000 loss... 0.0006429752102121711 accuracy 1.0\n",
      "i...36000 loss... 0.005984489805996418 accuracy 1.0\n",
      "i...37000 loss... 0.012566532008349895 accuracy 1.0\n",
      "i...38000 loss... 0.008703027851879597 accuracy 1.0\n",
      "i...39000 loss... 0.0025084801018238068 accuracy 1.0\n",
      "i...40000 loss... 0.0035251209046691656 accuracy 1.0\n",
      "saved to /home/id-none/myfile/models1/pretrained_lstm.ckpt-40000\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "saver=tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(0,40001):\n",
    "    nextBatch,nextBatchLabels=getTrainBatch();\n",
    "    #print(nextBatch.shape)\n",
    "    #print(nextBatchLabels)\n",
    "    sess.run(optimizer,{input_data:nextBatch,labels:nextBatchLabels})\n",
    "    if(i%1000==0 and i!=0):\n",
    "        loss_=sess.run(loss,{input_data:nextBatch,labels:nextBatchLabels})\n",
    "        accuracy_=sess.run(accuracy,{input_data:nextBatch,labels:nextBatchLabels})\n",
    "        print(\"i...{}\".format(i),\"loss... {}\".format(loss_),\"accuracy {}\".format(accuracy_))\n",
    "    if(i%10000==0 and i!=0):\n",
    "        save_path=saver.save(sess,\"/home/id-none/myfile/models1/pretrained_lstm.ckpt\",global_step=i)\n",
    "        print(\"saved to %s\"%save_path)\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n"
     ]
    }
   ],
   "source": [
    "# sess=tf.InteractiveSession()\n",
    "# saver=tf.train.Saver()\n",
    "# saver.restore(sess,\"C:/NLP/models1/pretrained_lstm.ckpt-20000\")\n",
    "# print('down')\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# in2 = np.load('C:/NLP//train_review.npy')\n",
    "# out2 = np.load('C:/NLP//train_lable.npy')\n",
    "# print(in2.shape) #输出（24500，250）\n",
    "# print(out2.shape)#输出（24500，2）\n",
    "\n",
    "# x_test=in2\n",
    "# y_test=out2\n",
    "# #print(X_train.shape)\n",
    "# #print(Y_train[1])\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "# arr=np.zeros([1,maxSeqLength])\n",
    "# print(arr.shape)\n",
    "# sum=0\n",
    "# for i in range(0,1000):\n",
    "#     labels1 = np.array([y_test[i]])\n",
    "#     arr = np.array([x_test[i]])\n",
    "#     #print(arr.shape)\n",
    "#     #print(labels1)\n",
    "#     #print(\"accuracy for test:\",(sess.run(accuracy,{input_data:arr,labels:labels1})))\n",
    "#     #print(\"labels1:\",labels1,\"....result for test:\",(sess.run(pre,{input_data:arr,labels:labels1})),\"accuracy for test:\",(sess.run(accuracy,{input_data:arr,labels:labels1})))\n",
    "#     sum=sum+sess.run(accuracy,{input_data:arr,labels:labels1})\n",
    "# print(sum)\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e+02, 1.46630e+04, 3.60000e+01, ..., 1.00000e+01,\n",
       "        7.70000e+01, 1.24700e+03],\n",
       "       [4.10000e+01, 3.97800e+03, 2.01534e+05, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.17000e+02, 2.01534e+05, 1.06900e+03, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [4.10000e+01, 8.35000e+02, 9.66800e+03, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [3.60000e+01, 3.55000e+02, 1.90000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [4.10000e+01, 1.14000e+03, 1.17000e+02, ..., 1.03000e+02,\n",
       "        1.56600e+03, 3.70000e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = np.load('test_review.npy')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/id-none/myfile/models1/pretrained_lstm.ckpt-40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 07:22:22.174885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:38:00.0, compute capability: 8.6\n",
      "2022-01-20 07:22:22.175400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22302 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "(22000, 250)\n",
      "(1, 250)\n",
      "result for test: [[0.85664546 0.14335456]]\n",
      "result for test: [[0.9939797  0.00602033]]\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "saver=tf.train.Saver()\n",
    "saver.restore(sess,\"/home/id-none/myfile/models1/pretrained_lstm.ckpt-40000\")\n",
    "print('down')\n",
    "\n",
    "#预测\n",
    "in3 = np.load('test.npy')\n",
    "\n",
    "\n",
    "x_test=in3\n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "arr=np.zeros([1,maxSeqLength])\n",
    "print(arr.shape)\n",
    "numpy_data=[]\n",
    "sum=0\n",
    "for i in range(0,2):\n",
    "    arr = np.array([x_test[i]])\n",
    "    print(\"result for test:\",(sess.run(pre,{input_data:arr})))\n",
    "    numpy_data.append(sess.run(pre,{input_data:arr}))\n",
    "    #print(\"labels1:\",labels1,\"....result for test:\",(sess.run(pre,{input_data:arr,labels:labels1})),\"accuracy for test:\",(sess.run(accuracy,{input_data:arr,labels:labels1})))\n",
    "    #sum=sum+sess.run(accuracy,{input_data:arr,labels:labels1})\n",
    "#print(sum)\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85664546 0.14335456]]\n",
      "[0.85664546 0.14335456]\n",
      "0.14335456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.85664546, 0.14335456]], dtype=float32),\n",
       " array([[0.9939797 , 0.00602033]], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(numpy_data[0])\n",
    "print(numpy_data[0][0])\n",
    "print(numpy_data[0][0][1])\n",
    "numpy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22000, 250)\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "result_data=[]\n",
    "print(in3.shape)\n",
    "for i in range(0,22000):\n",
    "    arr = np.array([x_test[i]])\n",
    "    result_data.append(sess.run(pre,{input_data:arr}))\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85664546 0.14335456]]\n"
     ]
    }
   ],
   "source": [
    "print(result_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9939797  0.00602033]]\n",
      "[0.9939797  0.00602033]\n"
     ]
    }
   ],
   "source": [
    "print(result_data[1])\n",
    "print(numpy_data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n"
     ]
    }
   ],
   "source": [
    "f=open('possubmission.txt','w')\n",
    "for i in range (22000):\n",
    "    #print(i)\n",
    "    f.write('\\n'+str(result_data[i][0][0]))\n",
    "f.close()\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n"
     ]
    }
   ],
   "source": [
    "g=open('negsubmission.txt','w')\n",
    "for i in range (22000):\n",
    "    #print(i)\n",
    "    g.write('\\n'+str(result_data[i][0][1]))\n",
    "g.close()\n",
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
